{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKFLCEtuAW0L",
        "outputId": "0fd13e7c-4430-44d3-f1af-bd15456875f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5PQVqdPCFyh",
        "outputId": "c60ebc4c-5f85-4a7c-e01c-60589e6419d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "\n",
            "Naive Bayes Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.97      0.77      0.86      8594\n",
            "  defacement       0.79      0.98      0.88      1913\n",
            "     malware       0.80      0.93      0.86       650\n",
            "    phishing       0.48      0.79      0.60      1867\n",
            "\n",
            "    accuracy                           0.81     13024\n",
            "   macro avg       0.76      0.87      0.80     13024\n",
            "weighted avg       0.87      0.81      0.83     13024\n",
            "\n",
            "Confusion Matrix:\n",
            "[[6650  299   98 1547]\n",
            " [  16 1880    2   15]\n",
            " [  11   19  603   17]\n",
            " [ 163  179   55 1470]]\n",
            "\n",
            "Support Vector Machine Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.94      0.98      0.96      8594\n",
            "  defacement       0.94      0.99      0.97      1913\n",
            "     malware       0.98      0.94      0.96       650\n",
            "    phishing       0.86      0.66      0.74      1867\n",
            "\n",
            "    accuracy                           0.93     13024\n",
            "   macro avg       0.93      0.89      0.91     13024\n",
            "weighted avg       0.93      0.93      0.93     13024\n",
            "\n",
            "Confusion Matrix:\n",
            "[[8385   16    1  192]\n",
            " [   6 1903    0    4]\n",
            " [  22    9  608   11]\n",
            " [ 538   96   10 1223]]\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Loading the dataset\n",
        "df = pd.read_csv('malicious_phish.csv')\n",
        "\n",
        "# Loading a random 10% sample of the data\n",
        "df_sample = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Preprocess the data\n",
        "X = df_sample['url']\n",
        "y = df_sample['type']\n",
        "\n",
        "# Encoding labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Spliting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Creating pipelines for both classifiers\n",
        "nb_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', SVC(kernel='rbf', random_state=42))\n",
        "])\n",
        "\n",
        "# Training both classifiers\n",
        "nb_pipeline.fit(X_train, y_train)\n",
        "svm_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Function to evaluate and print metrics\n",
        "def evaluate_classifier(pipeline, X_test, y_test, classifier_name):\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(f\"\\n{classifier_name} Results:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Evaluating both classifiers\n",
        "evaluate_classifier(nb_pipeline, X_test, y_test, \"Naive Bayes\")\n",
        "evaluate_classifier(svm_pipeline, X_test, y_test, \"Support Vector Machine\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Algorithm for URL Classification with Naive Bayes and SVM\n",
        "\n",
        "# 1. Install Required Packages:\n",
        "INSTALL imbalanced-learn\n",
        "\n",
        "# 2. Import Libraries:\n",
        "\n",
        "# 3. Load and Sample Data:\n",
        "\n",
        "# 4. Preprocess Data:\n",
        "EXTRACT 'url' COLUMN FROM df_sample INTO X\n",
        "EXTRACT 'type' COLUMN FROM df_sample INTO y\n",
        "INITIALIZE LabelEncoder AS le\n",
        "ENCODE y USING le\n",
        "\n",
        "# 5. Split Data:\n",
        "SPLIT X AND y INTO TRAINING AND TEST SETS WITH 80% TRAINING AND 20% TESTING\n",
        "\n",
        "# 6. Create Pipelines for Classifiers:\n",
        "## Naive Bayes Pipeline:\n",
        "INITIALIZE nb_pipeline AS Pipeline WITH:\n",
        "  - TfidfVectorizer\n",
        "  - SMOTE WITH SEED 42\n",
        "  - MultinomialNB\n",
        "\n",
        "## SVM Pipeline:\n",
        "INITIALIZE svm_pipeline AS Pipeline WITH:\n",
        "  - TfidfVectorizer\n",
        "  - SMOTE WITH SEED 42\n",
        "  - SVC WITH RBF KERNEL AND SEED 42\n",
        "\n",
        "# 7. Train Classifiers:\n",
        "TRAIN nb_pipeline USING TRAINING DATA\n",
        "TRAIN svm_pipeline USING TRAINING DATA\n",
        "\n",
        "# 8. Evaluate Classifiers:\n",
        "## Function to Evaluate Classifiers:\n",
        "DEFINE FUNCTION evaluate_classifier(pipeline, X_test, y_test, classifier_name):\n",
        "  PREDICT y_pred USING pipeline ON X_test\n",
        "  PRINT classifier_name AND EVALUATION RESULTS:\n",
        "    - classification_report OF y_test AND y_pred WITH TARGET NAMES FROM le\n",
        "    - confusion_matrix OF y_test AND y_pred\n",
        "\n",
        "## Evaluate Both Classifiers:\n",
        "CALL evaluate_classifier WITH nb_pipeline, X_test, y_test, AND 'Naive Bayes'\n",
        "CALL evaluate_classifier WITH svm_pipeline, X_test, y_test, AND 'Support Vector Machine'\n"
      ],
      "metadata": {
        "id": "-uunnUiI3Gwh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}